trials: 5
results_dir: results/mnist_add_new
dataset: mnist_add
num_workers: 8
batch_size: 2048
num_operands: 12
selected_digits:
  - [0,1,2]
  - [0,1,2]
  - [0,1,2]
  - [0,1,2]
  - [0,1,2,3,4]
  - [0,1,2,3,4]
  - [0,1,2,3,4]
  - [0,1,2,3,4]
  - [0,1,2,3,4,5,6,7,8,9]
  - [0,1,2,3,4,5,6,7,8,9]
  - [0,1,2,3,4,5,6,7,8,9]
  - [0,1,2,3,4,5,6,7,8,9]
threshold_labels: 30
noise_level: 0.0
max_epochs: 300
train_dataset_size: 10000
sampling_percent: 0.625
sampling_groups: True
c2y_layers: [128, 128]
skip_repr_evaluation: True

# Intervention Parameters
intervention_freq: 1
intervention_batch_size: 2048
intervention_policies:
    # - "intcem_policy"
    - "optimal_global_no_prior"

# DATASET VARIABLES
root_dir: /home/thomas/local
test_subsampling: 1
weight_loss: True
use_task_class_weights: True
check_val_every_n_epoch: 2

shared_params:
    top_k_accuracy: null
    save_model: True
    patience: 5
    emb_size: 16
    extra_dims: 0
    concept_loss_weight: 10
    learning_rate: 0.001
    weight_decay: 0.000004
    c_extractor_arch: resnet18
    optimizer: sgd
    bool: False
    early_stopping_monitor: val_loss
    early_stopping_mode: min
    early_stopping_delta: 0.0
    momentum: 0.9
    sigmoidal_prob: False
    training_intervention_prob: 0.25
runs:

    - architecture: 'ConceptBottleneckModel'
      extra_name: "Logit_long"
      sigmoidal_embedding: False
      concat_prob: False
      embedding_activation: "leakyrelu"
      bool: False
      extra_dims: 0
      sigmoidal_extra_capacity: False
      sigmoidal_prob: False
      max_epochs: 500