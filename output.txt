INFO:root:Results will be dumped in results/afa/mnist_afa
DEBUG:root:And the dataset's root directory is /home/xty20/data
[rank: 0] Global seed set to 42
DEBUG:root:		Updated concept group map (with 8 groups):
DEBUG:root:			0 -> [0, 1, 2]
DEBUG:root:			1 -> [3, 4, 5]
DEBUG:root:			2 -> [6, 7, 8]
DEBUG:root:			5 -> [9, 10, 11, 12, 13]
DEBUG:root:			8 -> [14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
DEBUG:root:			9 -> [24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
DEBUG:root:			10 -> [34, 35, 36, 37, 38, 39, 40, 41, 42, 43]
DEBUG:root:			11 -> [44, 45, 46, 47, 48, 49, 50, 51, 52, 53]
/home/xty20/cem/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/seed.py:47: LightningDeprecationWarning: `pytorch_lightning.utilities.seed.seed_everything` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.seed.seed_everything` instead.
  rank_zero_deprecation(
[rank: 0] Global seed set to 42
{
    "batch_size": 512,
    "c2y_layers": [
        128,
        128
    ],
    "c_extractor_arch": "Function: c_extractor_arch",
    "check_val_every_n_epoch": 2,
    "dataset": "mnist_add",
    "intervention_batch_size": 512,
    "intervention_freq": 1,
    "intervention_policies": [
        "intcem_policy",
        "optimal_greedy_no_prior"
    ],
    "max_epochs": 300,
    "noise_level": 0.0,
    "num_operands": 12,
    "num_workers": 8,
    "results_dir": "results/afa/mnist_afa",
    "root_dir": "/home/xty20/data",
    "runs": [
        {
            "architecture": "IntAwareConceptEmbeddingModel",
            "average_trajectory": true,
            "beta_a": 1,
            "beta_b": 3,
            "embedding_activation": "leakyrelu",
            "extra_name": "Retry_intervention_weight_{intervention_weight}_horizon_rate_{horizon_rate}_intervention_discount_{intervention_discount}_task_discount_{intervention_task_discount}_afa",
            "horizon_binary_representation": true,
            "horizon_rate": 1.005,
            "horizon_uniform_distr": true,
            "include_only_last_trajectory_loss": true,
            "include_task_trajectory_loss": true,
            "initial_horizon": 2,
            "initialize_discount": false,
            "int_model_layers": [
                128,
                128,
                64,
                64
            ],
            "int_model_use_bn": true,
            "intcem_task_loss_weight": 0,
            "intervention_discount": 1,
            "intervention_task_discount": 1.1,
            "intervention_task_loss_weight": 1,
            "intervention_weight": 1,
            "legacy_mode": false,
            "max_horizon": 6,
            "model_pretrain_path": null,
            "propagate_target_gradients": false,
            "task_loss_weight": 0,
            "tau": 1,
            "training_intervention_prob": 0.25,
            "use_concept_groups": true,
            "use_full_mask_distr": false,
            "use_horizon": false
        }
    ],
    "sampling_groups": true,
    "sampling_percent": 0.625,
    "selected_digits": [
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ]
    ],
    "shared_params": {
        "ac_model_config": {
            "affine_hids": [
                256,
                256
            ],
            "architecture": "flow",
            "batch_size": 512,
            "clip_gradient": 1,
            "coupling_hids": [
                256,
                256
            ],
            "decay_rate": 0.5,
            "decay_steps": 10000,
            "layer_cfg": [
                "LR",
                "CP2"
            ],
            "learning_rate": 1e-05,
            "linear_hids": [
                256,
                256
            ],
            "linear_rank": -1,
            "max_epochs": 100,
            "n_components": 40,
            "num_samples": 10,
            "optimizer": "adam",
            "prior": "autoreg",
            "prior_hids": [
                256,
                256
            ],
            "prior_layers": 2,
            "prior_units": 256,
            "rnncp_layers": 2,
            "rnncp_units": 256,
            "save_path": "/home/xty20/cem/results/afa/mnist_acflow_cem/acflow_model_trial_0.pt",
            "separate_flow_model_training": true,
            "transformations": [
                "AF",
                "TL",
                "TL",
                "TL",
                "TL",
                "AF"
            ]
        },
        "ac_model_nll_ratio": 0.5,
        "ac_model_rollouts": 1,
        "ac_model_weight": 2,
        "afa_model_config": {
            "act_fun": "relu",
            "clip_coef": 0.2,
            "clip_vloss": false,
            "ent_coef": 0.0,
            "normalize_advantages": false,
            "num_envs": 1,
            "ortho_init": false,
            "vf_coef": 1.0
        },
        "bool": false,
        "c_extractor_arch": "resnet18",
        "concept_loss_weight": 10,
        "early_stopping_delta": 0.0,
        "early_stopping_mode": "min",
        "early_stopping_monitor": "val_loss",
        "emb_size": 16,
        "extra_dims": 0,
        "learning_rate": 0.0001,
        "momentum": 0.9,
        "only_train_ac_model": false,
        "optimizer": "sgd",
        "patience": 5,
        "save_model": true,
        "separate_ac_model_training": true,
        "sigmoidal_prob": false,
        "top_k_accuracy": null,
        "training_intervention_prob": 0.25,
        "weight_decay": 4e-06
    },
    "skip_repr_evaluation": true,
    "test_dataset_size": 1024,
    "test_subsampling": 1,
    "threshold_labels": 30,
    "train_dataset_size": 5000,
    "trials": 1,
    "use_task_class_weights": true,
    "weight_loss": true
}
INFO:root:Training sample shape is: torch.Size([512, 12, 28, 28]) with type torch.FloatTensor
INFO:root:Training label shape is: torch.Size([512]) with type torch.FloatTensor
INFO:root:	Number of output classes: 1
INFO:root:Training concept shape is: torch.Size([512, 54]) with type torch.FloatTensor
INFO:root:	Number of training concepts: 54
INFO:root:Computing task class weights in the training dataset with size 10...
INFO:root:Setting log level to: "DEBUG"
Class distribution is: [0.471 0.529]
[TRIAL 1/1 BEGINS AT 21/04/2024 at 22:21:58
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]DEBUG:root:AC Model test results before training:

DEBUG:root:	test_accuracy: 0.509765625
DEBUG:root:	test_nll: 0.9262028932571411
DEBUG:root:AC Model input shape:	x:torch.Size([54])	b:torch.Size([54])	m:torch.Size([54])	y:torch.Size([])AC Data loader batch size: 512
DEBUG:root:Found AC flow model saved in results/afa/mnist_afa/acflow_model_trial_0.pt
DEBUG:root:Restarting run because we could not find test_accuracy_ACFlowModel in old results.

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
      test_accuracy             0.509765625
        test_nll            0.9262028932571411
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  6.04it/s]Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  6.16it/s]Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  6.14it/s]DEBUG:root:Setting ac model save path to be results/afa/mnist_afa/acflow_model_trial_0.pt
[rank: 0] Global seed set to 42
DEBUG:root:AC CBM loaded AC model checkpoint from results/afa/mnist_afa/acflow_model_trial_0.pt
DEBUG:root:Restarting run because we could not find val_acc_c_IntAwareConceptEmbeddingModelRetry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa in old results.

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
      test_accuracy             0.69921875
        test_nll            0.6249074339866638
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
AC Model test_accuracy: 69.92%, AC Model test_nll: 62.49% with 0 epochs in 0.00 seconds
[Training IntAwareConceptEmbeddingModelRetry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa_lambda_fold_1]
config:
<built-in function localtime>
	top_k_accuracy -> None
	save_model -> True
	patience -> 5
	emb_size -> 16
	extra_dims -> 0
	concept_loss_weight -> 10
	learning_rate -> 0.0001
	weight_decay -> 4e-06
	c_extractor_arch -> <function get_mnist_extractor_arch.<locals>.c_extractor_arch at 0x7f5fbea7e280>
	optimizer -> sgd
	bool -> False
	early_stopping_monitor -> val_loss
	early_stopping_mode -> min
	early_stopping_delta -> 0.0
	momentum -> 0.9
	sigmoidal_prob -> False
	training_intervention_prob -> 0.25
	separate_ac_model_training -> True
	only_train_ac_model -> False
	ac_model_config -> {'save_path': 'results/afa/mnist_afa/acflow_model_trial_0.pt', 'architecture': 'flow', 'max_epochs': 100, 'batch_size': 512, 'transformations': ['AF', 'TL', 'TL', 'TL', 'TL', 'AF'], 'layer_cfg': ['LR', 'CP2'], 'rnncp_units': 256, 'rnncp_layers': 2, 'linear_hids': [256, 256], 'linear_rank': -1, 'affine_hids': [256, 256], 'coupling_hids': [256, 256], 'prior': 'autoreg', 'n_components': 40, 'prior_units': 256, 'prior_layers': 2, 'prior_hids': [256, 256], 'separate_flow_model_training': True, 'optimizer': 'adam', 'learning_rate': 1e-05, 'decay_steps': 10000, 'decay_rate': 0.5, 'clip_gradient': 1, 'num_samples': 10}
	ac_model_nll_ratio -> 0.5
	ac_model_weight -> 2
	ac_model_rollouts -> 1
	afa_model_config -> {'act_fun': 'relu', 'ortho_init': False, 'vf_coef': 1.0, 'ent_coef': 0.0, 'clip_coef': 0.2, 'clip_vloss': False, 'normalize_advantages': False, 'num_envs': 1}
	trials -> 1
	results_dir -> results/afa/mnist_afa
	dataset -> mnist_add
	num_workers -> 8
	batch_size -> 512
	num_operands -> 12
	selected_digits -> [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
	threshold_labels -> 30
	noise_level -> 0.0
	max_epochs -> 300
	train_dataset_size -> 5000
	test_dataset_size -> 1024
	sampling_percent -> 0.625
	sampling_groups -> True
	c2y_layers -> [128, 128]
	skip_repr_evaluation -> True
	intervention_freq -> 1
	intervention_batch_size -> 512
	intervention_policies -> ['intcem_policy', 'optimal_greedy_no_prior']
	root_dir -> /home/xty20/data
	test_subsampling -> 1
	weight_loss -> True
	use_task_class_weights -> True
	check_val_every_n_epoch -> 2
	time_last_called -> 2024/04/21 at 22:21:47
	n_concepts -> 54
	n_tasks -> 1
	concept_map -> {0: [0, 1, 2], 1: [3, 4, 5], 2: [6, 7, 8], 5: [9, 10, 11, 12, 13], 8: [14, 15, 16, 17, 18, 19, 20, 21, 22, 23], 9: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33], 10: [34, 35, 36, 37, 38, 39, 40, 41, 42, 43], 11: [44, 45, 46, 47, 48, 49, 50, 51, 52, 53]}
	architecture -> IntAwareConceptEmbeddingModel
	extra_name -> Retry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa
	horizon_binary_representation -> True
	include_task_trajectory_loss -> True
	include_only_last_trajectory_loss -> True
	task_loss_weight -> 0
	intervention_weight -> 1
	intervention_task_loss_weight -> 1
	initial_horizon -> 2
	use_concept_groups -> True
	use_full_mask_distr -> False
	propagate_target_gradients -> False
	int_model_use_bn -> True
	int_model_layers -> [128, 128, 64, 64]
	intcem_task_loss_weight -> 0
	embedding_activation -> leakyrelu
	tau -> 1
	max_horizon -> 6
	horizon_uniform_distr -> True
	beta_a -> 1
	beta_b -> 3
	intervention_task_discount -> 1.1
	average_trajectory -> True
	use_horizon -> False
	initialize_discount -> False
	model_pretrain_path -> None
	horizon_rate -> 1.005
	intervention_discount -> 1
	legacy_mode -> False
[Number of parameters in model 4017976 ]
[Number of non-trainable parameters in model 2 ]
	Found cached model... loading it
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]DEBUG:root:Testing with budget None
Testing DataLoader 0:  50%|█████     | 1/2 [00:02<00:02,  2.56s/it]DEBUG:root:Testing with budget None
Testing DataLoader 0: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]DEBUG:root:Restarting run because we could not find test_acc_c_IntAwareConceptEmbeddingModelRetry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa in old results.

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test metric               DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     test_avg_c_y_acc          0.8217962962962964
      test_c_accuracy          0.9175925925925926
        test_c_auc             0.8188205598613777
         test_c_f1             0.8314107341520426
     test_concept_loss          9.02956771850586
    test_current_steps          3303.488037109375
    test_horizon_limit                 2.0
test_intervention_accuracy     0.7789999842643738
  test_intervention_loss       0.0401703342795372
test_intervention_task_loss    0.4406084418296814
         test_loss              9.510345458984375
    test_mask_accuracy                 0.0
      test_task_loss                   0.0
      test_y_accuracy                 0.726
        test_y_auc             0.8256568760855594
         test_y_f1             0.7015229476405948
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
val_c_acc: 91.76%, val_y_acc: 72.60%, val_c_auc: 81.88%, val_y_auc: 82.57% with 0 epochs in 0.00 seconds
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]DEBUG:root:Testing with budget None
Testing DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.23s/it]DEBUG:root:Testing with budget None
Testing DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]DEBUG:root:Restarting run because we could not find test_acc_y_intcem_policy_ints_ac_flow_model_split_0 in old results.
[rank: 0] Global seed set to 42
DEBUG:root:AC CBM loaded AC model checkpoint from results/afa/mnist_afa/acflow_model_trial_0.pt
DEBUG:root:Loading trained model from results/afa/mnist_afa/IntAwareConceptEmbeddingModelRetry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa_lambda_fold_1.pt
DEBUG:root:Intervention groups: [0, 1, 2, 3, 4, 5, 6, 7, 8]
DEBUG:root:Intervening in AFAModel
DEBUG:root:Intervening with 0 out of 8 concept groups
DEBUG:root:	For split 0 with 0 groups intervened
DEBUG:root:Testing with budget 0
DEBUG:root:Testing with budget 0
DEBUG:root:	Test AUC when intervening with 0 concept groups is 72.66% (accuracy is 72.66%).
DEBUG:root:Intervening with 1 out of 8 concept groups
DEBUG:root:	For split 0 with 1 groups intervened
DEBUG:root:Testing with budget 1
DEBUG:root:Testing with budget 1
DEBUG:root:	Test AUC when intervening with 1 concept groups is 77.05% (accuracy is 77.05%).
DEBUG:root:Intervening with 2 out of 8 concept groups
DEBUG:root:	For split 0 with 2 groups intervened
DEBUG:root:Testing with budget 2

[1]+  Stopped                 python experiments/run_experiments_rl.py -c experiments/configs/afa_configs/mnist_afa.yaml --debug
INFO:root:Results will be dumped in results/afa/mnist_afa
DEBUG:root:And the dataset's root directory is /home/xty20/data
[rank: 0] Global seed set to 42
DEBUG:root:		Updated concept group map (with 8 groups):
DEBUG:root:			0 -> [0, 1, 2]
DEBUG:root:			1 -> [3, 4, 5]
DEBUG:root:			2 -> [6, 7, 8]
DEBUG:root:			5 -> [9, 10, 11, 12, 13]
DEBUG:root:			8 -> [14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
DEBUG:root:			9 -> [24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
DEBUG:root:			10 -> [34, 35, 36, 37, 38, 39, 40, 41, 42, 43]
DEBUG:root:			11 -> [44, 45, 46, 47, 48, 49, 50, 51, 52, 53]
/home/xty20/cem/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/seed.py:47: LightningDeprecationWarning: `pytorch_lightning.utilities.seed.seed_everything` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.seed.seed_everything` instead.
  rank_zero_deprecation(
[rank: 0] Global seed set to 42
{
    "batch_size": 512,
    "c2y_layers": [
        128,
        128
    ],
    "c_extractor_arch": "Function: c_extractor_arch",
    "check_val_every_n_epoch": 2,
    "dataset": "mnist_add",
    "intervention_batch_size": 512,
    "intervention_freq": 1,
    "intervention_policies": [
        "intcem_policy",
        "optimal_greedy_no_prior"
    ],
    "max_epochs": 300,
    "noise_level": 0.0,
    "num_operands": 12,
    "num_workers": 8,
    "results_dir": "results/afa/mnist_afa",
    "root_dir": "/home/xty20/data",
    "runs": [
        {
            "architecture": "IntAwareConceptEmbeddingModel",
            "average_trajectory": true,
            "beta_a": 1,
            "beta_b": 3,
            "embedding_activation": "leakyrelu",
            "extra_name": "Retry_intervention_weight_{intervention_weight}_horizon_rate_{horizon_rate}_intervention_discount_{intervention_discount}_task_discount_{intervention_task_discount}_afa",
            "horizon_binary_representation": true,
            "horizon_rate": 1.005,
            "horizon_uniform_distr": true,
            "include_only_last_trajectory_loss": true,
            "include_task_trajectory_loss": true,
            "initial_horizon": 2,
            "initialize_discount": false,
            "int_model_layers": [
                128,
                128,
                64,
                64
            ],
            "int_model_use_bn": true,
            "intcem_task_loss_weight": 0,
            "intervention_discount": 1,
            "intervention_task_discount": 1.1,
            "intervention_task_loss_weight": 1,
            "intervention_weight": 1,
            "legacy_mode": false,
            "max_horizon": 6,
            "model_pretrain_path": null,
            "propagate_target_gradients": false,
            "task_loss_weight": 0,
            "tau": 1,
            "training_intervention_prob": 0.25,
            "use_concept_groups": true,
            "use_full_mask_distr": false,
            "use_horizon": false
        }
    ],
    "sampling_groups": true,
    "sampling_percent": 0.625,
    "selected_digits": [
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ],
        [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
        ]
    ],
    "shared_params": {
        "ac_model_config": {
            "affine_hids": [
                256,
                256
            ],
            "architecture": "flow",
            "batch_size": 512,
            "clip_gradient": 1,
            "coupling_hids": [
                256,
                256
            ],
            "decay_rate": 0.5,
            "decay_steps": 10000,
            "layer_cfg": [
                "LR",
                "CP2"
            ],
            "learning_rate": 1e-05,
            "linear_hids": [
                256,
                256
            ],
            "linear_rank": -1,
            "max_epochs": 100,
            "n_components": 40,
            "num_samples": 10,
            "optimizer": "adam",
            "prior": "autoreg",
            "prior_hids": [
                256,
                256
            ],
            "prior_layers": 2,
            "prior_units": 256,
            "rnncp_layers": 2,
            "rnncp_units": 256,
            "save_path": "/home/xty20/cem/results/afa/mnist_acflow_cem/acflow_model_trial_0.pt",
            "separate_flow_model_training": true,
            "transformations": [
                "AF",
                "TL",
                "TL",
                "TL",
                "TL",
                "AF"
            ]
        },
        "ac_model_nll_ratio": 0.5,
        "ac_model_rollouts": 1,
        "ac_model_weight": 2,
        "afa_model_config": {
            "act_fun": "relu",
            "clip_coef": 0.2,
            "clip_vloss": false,
            "ent_coef": 0.0,
            "normalize_advantages": false,
            "num_envs": 1,
            "ortho_init": false,
            "vf_coef": 1.0
        },
        "bool": false,
        "c_extractor_arch": "resnet18",
        "concept_loss_weight": 10,
        "early_stopping_delta": 0.0,
        "early_stopping_mode": "min",
        "early_stopping_monitor": "val_loss",
        "emb_size": 16,
        "extra_dims": 0,
        "learning_rate": 0.0001,
        "momentum": 0.9,
        "only_train_ac_model": false,
        "optimizer": "sgd",
        "patience": 5,
        "save_model": true,
        "separate_ac_model_training": true,
        "sigmoidal_prob": false,
        "top_k_accuracy": null,
        "training_intervention_prob": 0.25,
        "weight_decay": 4e-06
    },
    "skip_repr_evaluation": true,
    "test_dataset_size": 1024,
    "test_subsampling": 1,
    "threshold_labels": 30,
    "train_dataset_size": 5000,
    "trials": 1,
    "use_task_class_weights": true,
    "weight_loss": true
}
INFO:root:Training sample shape is: torch.Size([512, 12, 28, 28]) with type torch.FloatTensor
INFO:root:Training label shape is: torch.Size([512]) with type torch.FloatTensor
INFO:root:	Number of output classes: 1
INFO:root:Training concept shape is: torch.Size([512, 54]) with type torch.FloatTensor
INFO:root:	Number of training concepts: 54
INFO:root:Computing task class weights in the training dataset with size 10...
INFO:root:Setting log level to: "DEBUG"
Class distribution is: [0.471 0.529]
[TRIAL 1/1 BEGINS AT 21/04/2024 at 22:34:34
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:  50%|█████     | 1/2 [00:07<00:07,  7.63s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:15<00:00,  7.57s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:15<00:00,  7.57s/it]DEBUG:root:AC Model test results before training:

DEBUG:root:	test_accuracy: 0.509765625
DEBUG:root:	test_nll: 0.9262030124664307
DEBUG:root:AC Model input shape:	x:torch.Size([54])	b:torch.Size([54])	m:torch.Size([54])	y:torch.Size([])AC Data loader batch size: 512
DEBUG:root:Found AC flow model saved in results/afa/mnist_afa/acflow_model_trial_0.pt
DEBUG:root:Restarting run because we could not find test_accuracy_ACFlowModel in old results.

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
      test_accuracy             0.509765625
        test_nll            0.9262030124664307
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:  50%|█████     | 1/2 [00:07<00:07,  7.72s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:15<00:00,  7.68s/it]Testing DataLoader 0: 100%|██████████| 2/2 [00:15<00:00,  7.68s/it]DEBUG:root:Setting ac model save path to be results/afa/mnist_afa/acflow_model_trial_0.pt
[rank: 0] Global seed set to 42
DEBUG:root:AC CBM loaded AC model checkpoint from results/afa/mnist_afa/acflow_model_trial_0.pt
DEBUG:root:Restarting run because we could not find val_acc_c_IntAwareConceptEmbeddingModelRetry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa in old results.

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
       Test metric             DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
      test_accuracy            0.6865234375
        test_nll            0.6203749179840088
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
AC Model test_accuracy: 68.65%, AC Model test_nll: 62.04% with 0 epochs in 0.00 seconds
[Training IntAwareConceptEmbeddingModelRetry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa_lambda_fold_1]
config:
<built-in function localtime>
	top_k_accuracy -> None
	save_model -> True
	patience -> 5
	emb_size -> 16
	extra_dims -> 0
	concept_loss_weight -> 10
	learning_rate -> 0.0001
	weight_decay -> 4e-06
	c_extractor_arch -> <function get_mnist_extractor_arch.<locals>.c_extractor_arch at 0x7fe9d8ea9280>
	optimizer -> sgd
	bool -> False
	early_stopping_monitor -> val_loss
	early_stopping_mode -> min
	early_stopping_delta -> 0.0
	momentum -> 0.9
	sigmoidal_prob -> False
	training_intervention_prob -> 0.25
	separate_ac_model_training -> True
	only_train_ac_model -> False
	ac_model_config -> {'save_path': 'results/afa/mnist_afa/acflow_model_trial_0.pt', 'architecture': 'flow', 'max_epochs': 100, 'batch_size': 512, 'transformations': ['AF', 'TL', 'TL', 'TL', 'TL', 'AF'], 'layer_cfg': ['LR', 'CP2'], 'rnncp_units': 256, 'rnncp_layers': 2, 'linear_hids': [256, 256], 'linear_rank': -1, 'affine_hids': [256, 256], 'coupling_hids': [256, 256], 'prior': 'autoreg', 'n_components': 40, 'prior_units': 256, 'prior_layers': 2, 'prior_hids': [256, 256], 'separate_flow_model_training': True, 'optimizer': 'adam', 'learning_rate': 1e-05, 'decay_steps': 10000, 'decay_rate': 0.5, 'clip_gradient': 1, 'num_samples': 10}
	ac_model_nll_ratio -> 0.5
	ac_model_weight -> 2
	ac_model_rollouts -> 1
	afa_model_config -> {'act_fun': 'relu', 'ortho_init': False, 'vf_coef': 1.0, 'ent_coef': 0.0, 'clip_coef': 0.2, 'clip_vloss': False, 'normalize_advantages': False, 'num_envs': 1}
	trials -> 1
	results_dir -> results/afa/mnist_afa
	dataset -> mnist_add
	num_workers -> 8
	batch_size -> 512
	num_operands -> 12
	selected_digits -> [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
	threshold_labels -> 30
	noise_level -> 0.0
	max_epochs -> 300
	train_dataset_size -> 5000
	test_dataset_size -> 1024
	sampling_percent -> 0.625
	sampling_groups -> True
	c2y_layers -> [128, 128]
	skip_repr_evaluation -> True
	intervention_freq -> 1
	intervention_batch_size -> 512
	intervention_policies -> ['intcem_policy', 'optimal_greedy_no_prior']
	root_dir -> /home/xty20/data
	test_subsampling -> 1
	weight_loss -> True
	use_task_class_weights -> True
	check_val_every_n_epoch -> 2
	time_last_called -> 2024/04/21 at 22:34:24
	n_concepts -> 54
	n_tasks -> 1
	concept_map -> {0: [0, 1, 2], 1: [3, 4, 5], 2: [6, 7, 8], 5: [9, 10, 11, 12, 13], 8: [14, 15, 16, 17, 18, 19, 20, 21, 22, 23], 9: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33], 10: [34, 35, 36, 37, 38, 39, 40, 41, 42, 43], 11: [44, 45, 46, 47, 48, 49, 50, 51, 52, 53]}
	architecture -> IntAwareConceptEmbeddingModel
	extra_name -> Retry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa
	horizon_binary_representation -> True
	include_task_trajectory_loss -> True
	include_only_last_trajectory_loss -> True
	task_loss_weight -> 0
	intervention_weight -> 1
	intervention_task_loss_weight -> 1
	initial_horizon -> 2
	use_concept_groups -> True
	use_full_mask_distr -> False
	propagate_target_gradients -> False
	int_model_use_bn -> True
	int_model_layers -> [128, 128, 64, 64]
	intcem_task_loss_weight -> 0
	embedding_activation -> leakyrelu
	tau -> 1
	max_horizon -> 6
	horizon_uniform_distr -> True
	beta_a -> 1
	beta_b -> 3
	intervention_task_discount -> 1.1
	average_trajectory -> True
	use_horizon -> False
	initialize_discount -> False
	model_pretrain_path -> None
	horizon_rate -> 1.005
	intervention_discount -> 1
	legacy_mode -> False
[Number of parameters in model 4017976 ]
[Number of non-trainable parameters in model 2 ]
	Found cached model... loading it
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/2 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]DEBUG:root:Testing with budget None
Testing DataLoader 0:  50%|█████     | 1/2 [01:39<01:39, 99.82s/it]DEBUG:root:Testing with budget None
Testing DataLoader 0: 100%|██████████| 2/2 [02:39<00:00, 79.67s/it]Testing DataLoader 0: 100%|██████████| 2/2 [02:39<00:00, 79.68s/it]DEBUG:root:Restarting run because we could not find test_acc_c_IntAwareConceptEmbeddingModelRetry_intervention_weight_1_horizon_rate_1.005_intervention_discount_1_task_discount_1.1_afa in old results.
DEBUG:fsspec.local:open file: /home/xty20/cem/hpc_ckpt_1.ckpt

────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
        Test metric               DataLoader 0
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
     test_avg_c_y_acc          0.8217870370370369
      test_c_accuracy          0.9175740740740741
        test_c_auc             0.8188104963457463
         test_c_f1             0.8313637744696336
     test_concept_loss          9.029860496520996
    test_current_steps          3303.488037109375
    test_horizon_limit                 2.0
test_intervention_accuracy     0.7789999842643738
  test_intervention_loss       0.03907260298728943
test_intervention_task_loss    0.4389403164386749
         test_loss              9.507872581481934
    test_mask_accuracy                 0.0
      test_task_loss                   0.0
      test_y_accuracy                 0.726
        test_y_auc             0.8256408349877151
         test_y_f1             0.7015229476405948
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
val_c_acc: 91.76%, val_y_acc: 72.60%, val_c_auc: 81.88%, val_y_auc: 82.56% with 0 epochs in 0.00 seconds
> /home/xty20/cem/venv/lib/python3.8/site-packages/cem-1.1.0-py3.8.egg/cem/train/training.py(537)_inner_call()
-> test_results["test_c_accuracy"],
(Pdb) *** NameError: name 'ls' is not defined
(Pdb) *** NameError: name 'self' is not defined
(Pdb) Traceback (most recent call last):
  File "experiments/run_experiments_rl.py", line 894, in <module>
    main(
  File "experiments/run_experiments_rl.py", line 458, in main
    training.train_model(
  File "/home/xty20/cem/venv/lib/python3.8/site-packages/cem-1.1.0-py3.8.egg/cem/train/training.py", line 571, in train_model
  File "/home/xty20/cem/venv/lib/python3.8/site-packages/cem-1.1.0-py3.8.egg/cem/train/utils.py", line 90, in load_call
  File "/home/xty20/cem/venv/lib/python3.8/site-packages/cem-1.1.0-py3.8.egg/cem/train/training.py", line 537, in _inner_call
  File "/home/xty20/cem/venv/lib/python3.8/site-packages/cem-1.1.0-py3.8.egg/cem/train/training.py", line 537, in _inner_call
  File "/usr/local/software/master/python/3.8/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/software/master/python/3.8/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
